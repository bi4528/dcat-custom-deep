{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e23c27",
   "metadata": {},
   "source": [
    "# Mouse Human Ontology Matching Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cdfb07",
   "metadata": {},
   "source": [
    "## Setup & Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046417c3",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "789e3d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/d/hpc/home/bi4528/ckanenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef, RDFS, RDF, OWL, Literal, Namespace\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# import re\n",
    "import yaml\n",
    "from typing import List, Dict, Optional\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4a1b26",
   "metadata": {},
   "source": [
    "#### Load paths and constans from configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4467d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"./config.yaml\"\n",
    "with open(CONFIG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9118162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALIGNMENT_RDF_PATH = config[\"paths\"][\"mouse_human_alignment\"]\n",
    "\n",
    "HUMAN_OWL_PATH = config[\"paths\"][\"human_ontology\"]\n",
    "HUMAN_INDEX_PATH = config[\"paths\"][\"human_index\"]\n",
    "HUMAN_ID_TRACKER_PATH = config[\"paths\"][\"human_id_tracker\"]\n",
    "HUMAN_TERMS_JSON_PATH = config[\"paths\"][\"human_terms_json\"]\n",
    "\n",
    "MOUSE_OWL_PATH = config[\"paths\"][\"mouse_ontology\"]\n",
    "MOUSE_INDEX_PATH = config[\"paths\"][\"mouse_index\"]\n",
    "MOUSE_ID_TRACKER_PATH = config[\"paths\"][\"mouse_id_tracker\"]\n",
    "MOUSE_TERMS_JSON_PATH = config[\"paths\"][\"mouse_terms_json\"]\n",
    "\n",
    "HUMAN_NAMESPACE = \"http://human.owl#\"\n",
    "MOUSE_NAMESPACE = \"http://mouse.owl#\"\n",
    "\n",
    "EMBEDDING_MODEL_NAME = config[\"models\"][\"embedding_model\"]\n",
    "OBO = Namespace(\"http://www.geneontology.org/formats/oboInOwl#\")\n",
    "\n",
    "TESTSET_PATH = config[\"paths\"][\"mouse_testset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93195abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./src/.hf_token\", \"r\") as f:\n",
    "            hf_token = f.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d533de",
   "metadata": {},
   "source": [
    "#### Utils functions for ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b591d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(path):\n",
    "    graph = Graph()\n",
    "    graph.parse(path)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b9a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(graph, uri):\n",
    "    label = graph.value(uri, RDFS.label)\n",
    "    return str(label) if isinstance(label, Literal) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a86a2dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_related_uris(graph, subject, predicate):\n",
    "    \"\"\"Dereferences URIs linked by the predicate and returns their rdfs:label.\"\"\"\n",
    "    values = []\n",
    "    for obj in graph.objects(subject, predicate):\n",
    "        label = get_label(graph, obj)\n",
    "        if label:\n",
    "            values.append(label)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93f7df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_superclass_labels(graph, subject):\n",
    "    \"\"\"Get human-readable labels of direct superclasses.\"\"\"\n",
    "    super_labels = []\n",
    "    for superclass in graph.objects(subject, RDFS.subClassOf):\n",
    "        if isinstance(superclass, URIRef):\n",
    "            label = get_label(graph, superclass)\n",
    "            if label:\n",
    "                super_labels.append(label)\n",
    "        elif (superclass, RDF.type, OWL.Restriction) in graph:\n",
    "            filler = graph.value(superclass, OWL.someValuesFrom)\n",
    "            if isinstance(filler, URIRef):\n",
    "                super_labels.append(str(filler).split(\"#\")[-1])\n",
    "    return super_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fffb06",
   "metadata": {},
   "source": [
    "#### Utils functions for generating terms JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a4491df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_text_for_embedding(label, definition=None, synonyms=None, superclasses=None):\n",
    "    parts = [f\"Concept: {label}\"]\n",
    "\n",
    "    if synonyms:\n",
    "        parts.append(f\"Also known as: {', '.join(synonyms)}\")\n",
    "\n",
    "    if superclasses:\n",
    "        parts.append(f\"Part of: {', '.join(superclasses)}\")\n",
    "\n",
    "    if definition:\n",
    "        parts.append(f\"Defined as: {definition}\")\n",
    "\n",
    "    return \". \".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a3542f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_enriched_terms(graph):\n",
    "    terms = []\n",
    "    for s in graph.subjects(RDF.type, OWL.Class):\n",
    "        label = get_label(graph, s)\n",
    "        if not label:\n",
    "            continue\n",
    "\n",
    "        definition = extract_related_uris(graph, s, OBO.hasDefinition)\n",
    "        synonyms = extract_related_uris(graph, s, OBO.hasRelatedSynonym)\n",
    "        superclasses = extract_superclass_labels(graph, s)\n",
    "\n",
    "        enriched_text = build_text_for_embedding(\n",
    "            label=label,\n",
    "            definition=definition[0] if definition else None,\n",
    "            synonyms=synonyms,\n",
    "            superclasses=superclasses\n",
    "        )\n",
    "\n",
    "        terms.append({\n",
    "            \"uri\": str(s),\n",
    "            \"label\": label,\n",
    "            \"definition\": definition[0] if definition else \"\",\n",
    "            \"synonyms\": synonyms,\n",
    "            \"superclasses\": superclasses,\n",
    "            \"text_for_embedding\": enriched_text\n",
    "        })\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8cb1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_embeddings(embeddings: np.ndarray) -> np.ndarray:\n",
    "    return embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d9c7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ontology_indexing(ontology_json, faiss_index_path, id_tracker_json):\n",
    "\n",
    "    with open(ontology_json, \"r\", encoding=\"utf-8\") as f:\n",
    "            ontology_terms = json.load(f)\n",
    "\n",
    "    texts = []\n",
    "    ids = []\n",
    "    valid_terms = []\n",
    "\n",
    "    for i, term in enumerate(ontology_terms):\n",
    "        text = term.get(\"text_for_embedding\")\n",
    "        if not text:\n",
    "            raise ValueError(\"Missing 'text_for_embedding'\")\n",
    "        texts.append(text)\n",
    "        ids.append(abs(hash(term[\"uri\"])) % (10**12))\n",
    "        valid_terms.append(term)\n",
    "\n",
    "    # Embedding\n",
    "    model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "    embeddings = model.encode(texts, batch_size=16, show_progress_bar=True)\n",
    "    embeddings = normalize_embeddings(np.array(embeddings))\n",
    "\n",
    "    # FAISS indexing\n",
    "    dimension = embeddings.shape[1]\n",
    "    base_index = faiss.IndexFlatIP(dimension)\n",
    "    index = faiss.IndexIDMap(base_index)\n",
    "    index.add_with_ids(embeddings, np.array(ids))\n",
    "    os.makedirs(os.path.dirname(faiss_index_path), exist_ok=True)\n",
    "    faiss.write_index(index, faiss_index_path)\n",
    "\n",
    "    # Save ID tracker\n",
    "    id_map = {str(id_): term for id_, term in zip(ids, valid_terms)}\n",
    "    with open(id_tracker_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(id_map, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432b5389",
   "metadata": {},
   "source": [
    "#### Utils for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d55dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_by_label_similarity(source_label: str, candidates: List[Dict], weight_faiss: float = 0.7, weight_label: float = 0.3) -> List[Dict]:\n",
    "    \"\"\"Combines semantic score and lexical similarity to rerank matches.\"\"\"\n",
    "    reranked = []\n",
    "    for match in candidates:\n",
    "        label_sim = fuzz.ratio(source_label, match[\"label\"]) / 100\n",
    "        combined_score = weight_faiss * match[\"score\"] + weight_label * label_sim\n",
    "        reranked.append({**match, \"combined_score\": combined_score})\n",
    "    return sorted(reranked, key=lambda x: x[\"combined_score\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23ca8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index_lookup(index_path: str, id_tracker_path: str):\n",
    "    index = faiss.read_index(index_path)\n",
    "    with open(id_tracker_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        id_map = {int(k): v for k, v in json.load(f).items()}\n",
    "    return index, id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "727dc5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faiss_batch_search(embeddings: np.ndarray, index, top_k: int):\n",
    "    return index.search(embeddings, top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54b1ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_reverse_matches(\n",
    "    target_terms: List[Dict],\n",
    "    reverse_index,\n",
    "    reverse_id_map: Dict[int, Dict],\n",
    "    model,\n",
    "    top_k: int = 1\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Computes best reverse matches (target → source).\n",
    "    Returns dict: target_uri → best source_uri.\n",
    "    \"\"\"\n",
    "    reverse_lookup = {}\n",
    "\n",
    "    valid_terms = [t for t in target_terms if t.get(\"text_for_embedding\")]\n",
    "    texts = [t[\"text_for_embedding\"] for t in valid_terms]\n",
    "    uris = [t[\"uri\"] for t in valid_terms]\n",
    "\n",
    "    # Batch encoding\n",
    "    embeddings = model.encode(texts, batch_size=32, show_progress_bar=True)\n",
    "    embeddings = normalize_embeddings(np.array(embeddings).astype(np.float32))\n",
    "\n",
    "    # Batch FAISS search\n",
    "    D, I = reverse_index.search(embeddings, top_k)\n",
    "\n",
    "    for i, (indices, scores) in enumerate(zip(I, D)):\n",
    "        best_idx = indices[0]\n",
    "        if best_idx == -1:\n",
    "            continue\n",
    "        match = reverse_id_map.get(best_idx)\n",
    "        if match:\n",
    "            reverse_lookup[uris[i]] = match[\"uri\"]\n",
    "\n",
    "    return reverse_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "329a0e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_reverse_matches_topk(\n",
    "    target_terms: list,\n",
    "    reverse_index,\n",
    "    reverse_id_map: dict,\n",
    "    model,\n",
    "    top_k: int = 5\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Computes top-k reverse matches (target → source).\n",
    "    Returns dict: target_uri → list of source_uris.\n",
    "    \"\"\"\n",
    "    reverse_lookup_k = {}\n",
    "\n",
    "    valid_terms = [t for t in target_terms if t.get(\"text_for_embedding\")]\n",
    "    texts = [t[\"text_for_embedding\"] for t in valid_terms]\n",
    "    uris = [t[\"uri\"] for t in valid_terms]\n",
    "\n",
    "    # Batch encoding\n",
    "    embeddings = model.encode(texts, batch_size=32, show_progress_bar=True)\n",
    "    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "\n",
    "    # Batch FAISS search\n",
    "    D, I = reverse_index.search(np.array(embeddings).astype(np.float32), top_k)\n",
    "\n",
    "    for i, indices in enumerate(I):\n",
    "        matches = [reverse_id_map[idx][\"uri\"] for idx in indices if idx != -1 and reverse_id_map.get(idx)]\n",
    "        reverse_lookup_k[uris[i]] = matches\n",
    "\n",
    "    return reverse_lookup_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3d2c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_terms(terms: List[Dict], model) -> np.ndarray:\n",
    "    texts = [t[\"text_for_embedding\"] for t in terms if t.get(\"text_for_embedding\")]\n",
    "    return normalize_embeddings(model.encode(texts, batch_size=32, show_progress_bar=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06e062ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_faiss_results(source_terms, D, I, target_id_map):\n",
    "    matches = []\n",
    "    for i, (distances, indices) in enumerate(zip(D, I)):\n",
    "        src = source_terms[i]\n",
    "        results = []\n",
    "        for idx, score in zip(indices, distances):\n",
    "            if idx == -1:\n",
    "                continue\n",
    "            t = target_id_map.get(idx)\n",
    "            if not t:\n",
    "                continue\n",
    "            results.append({\n",
    "                \"uri\": t[\"uri\"],\n",
    "                \"label\": t[\"label\"],\n",
    "                \"score\": float(score)\n",
    "            })\n",
    "        matches.append({\n",
    "            \"source_uri\": src[\"uri\"],\n",
    "            \"source_label\": src[\"label\"],\n",
    "            \"top_k_matches\": results\n",
    "        })\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7931f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"google/gemma-2b-it\"  # or gemma-7b-it\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=\"auto\",  # or torch.float16\n",
    "#     token=hf_token\n",
    "# )\n",
    "\n",
    "# llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aedce14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rerank_with_gemma_batched(source_batch, llm, max_tokens=512):\n",
    "#     \"\"\"\n",
    "#     Batched reranking using Gemma.\n",
    "\n",
    "#     Args:\n",
    "#         source_batch: List of (source_label, candidate_matches), where:\n",
    "#                       - source_label is str\n",
    "#                       - candidate_matches is List[Dict] with 'label', 'uri', 'comment'\n",
    "#         llm: Hugging Face pipeline (text-generation)\n",
    "#         max_tokens: Max tokens to generate\n",
    "\n",
    "#     Returns:\n",
    "#         List of best candidate dicts (one per input), or None if no match\n",
    "#     \"\"\"\n",
    "#     prompts = []\n",
    "\n",
    "#     for source_label, candidates in source_batch:\n",
    "#         prompt = f\"\"\"You are an expert in biomedical ontologies.\n",
    "# Given the source concept: \"{source_label}\", choose the best matching target concept from the list below.\n",
    "# Respond with only the label of the best match.\n",
    "\n",
    "# Target candidates:\n",
    "# \"\"\"\n",
    "#         for c in candidates:\n",
    "#             label = c[\"label\"]\n",
    "#             comment = c.get(\"comment\", \"\")\n",
    "#             prompt += f\"- {label}: {comment}\\n\"\n",
    "\n",
    "#         prompt += \"\\nBest match:\"\n",
    "#         prompts.append(prompt)\n",
    "\n",
    "#     responses = llm(prompts, max_new_tokens=16, do_sample=False)\n",
    "\n",
    "#     best_candidates = []\n",
    "#     for (source_label, candidates), resp in zip(source_batch, responses):\n",
    "#         try:\n",
    "#             generated = resp[\"generated_text\"]\n",
    "#             selected_label = generated.split(\"Best match:\")[-1].strip().split(\"\\n\")[0]\n",
    "\n",
    "#             best = next((c for c in candidates if selected_label.lower() in c[\"label\"].lower()), None)\n",
    "#             best_candidates.append(best)\n",
    "#         except Exception as e:\n",
    "#             best_candidates.append(None)\n",
    "\n",
    "#     return best_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bcfb0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def batch(iterable, size):\n",
    "#     for i in range(0, len(iterable), size):\n",
    "#         yield iterable[i:i+size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c54f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_label_reranking(matches: List[Dict]):\n",
    "    reranked = []\n",
    "    for match in matches:\n",
    "        ranked = rerank_by_label_similarity(match[\"source_label\"], match[\"top_k_matches\"])\n",
    "        match[\"top_k_matches\"] = ranked\n",
    "        match[\"top_match\"] = ranked[0] if ranked else None\n",
    "        reranked.append(match)\n",
    "    return reranked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ffeab",
   "metadata": {},
   "source": [
    "#### Loading RDF into graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b776c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_graph = load_graph(MOUSE_OWL_PATH)\n",
    "human_graph = load_graph(HUMAN_OWL_PATH)\n",
    "alignment_graph = load_graph(ALIGNMENT_RDF_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf48b3",
   "metadata": {},
   "source": [
    "#### Loading embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0e6e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038506e9",
   "metadata": {},
   "source": [
    "#### Generate enriched JSON of ontology terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d7e9de",
   "metadata": {},
   "source": [
    "Generate enriched terms for human ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9379a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_terms = extract_enriched_terms(human_graph)\n",
    "\n",
    "with open(HUMAN_TERMS_JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(human_terms, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e4d5ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3298"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(human_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79e09ec",
   "metadata": {},
   "source": [
    "Generate enriched terms for mouse ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e752a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_terms = extract_enriched_terms(mouse_graph)\n",
    "\n",
    "with open(MOUSE_TERMS_JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(mouse_terms, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2e313ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2737"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mouse_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327aca2",
   "metadata": {},
   "source": [
    "#### Ontology indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68942e1f",
   "metadata": {},
   "source": [
    "Create and populate FAISS with human entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c1e2b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 207/207 [00:25<00:00,  8.04it/s]\n"
     ]
    }
   ],
   "source": [
    "ontology_indexing(ontology_json=HUMAN_TERMS_JSON_PATH, faiss_index_path=HUMAN_INDEX_PATH, id_tracker_json=HUMAN_ID_TRACKER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f5a39c",
   "metadata": {},
   "source": [
    "Create and populate FAISS with mouse entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57e43803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 172/172 [00:04<00:00, 38.54it/s]\n"
     ]
    }
   ],
   "source": [
    "ontology_indexing(ontology_json=MOUSE_TERMS_JSON_PATH, faiss_index_path=MOUSE_INDEX_PATH, id_tracker_json=MOUSE_ID_TRACKER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e0478",
   "metadata": {},
   "source": [
    "#### Execute matching on mouse human pair of ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed62e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_index = faiss.read_index(HUMAN_INDEX_PATH)\n",
    "with open(HUMAN_ID_TRACKER_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    human_id_map = {int(k): v for k, v in json.load(f).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d373bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_index = faiss.read_index(MOUSE_INDEX_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b705e5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 86/86 [00:04<00:00, 21.34it/s]\n"
     ]
    }
   ],
   "source": [
    "embs = embed_terms(mouse_terms, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7f0a5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 104/104 [00:12<00:00,  8.42it/s]\n"
     ]
    }
   ],
   "source": [
    "embs_h = embed_terms(human_terms, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "884de1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3298"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(human_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "15effa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len match: 2737\n",
      "len match: 2737\n"
     ]
    }
   ],
   "source": [
    "# Step-by-step matching\n",
    "D, I = faiss_batch_search(embs, human_index, top_k=5)\n",
    "matches = map_faiss_results(mouse_terms, D, I, human_id_map)\n",
    "\n",
    "output_path = \"./data/datasets/anatomy-dataset/mouse_to_human_matches_unranked.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(matches, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"len match: {len(matches)}\")\n",
    "\n",
    "# Optional refinements\n",
    "matches = apply_label_reranking(matches)\n",
    "\n",
    "output_path = \"./data/datasets/anatomy-dataset/mouse_to_human_matches_ranked.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(matches, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"len match: {len(matches)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "98265564",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_index = faiss.read_index(MOUSE_INDEX_PATH)\n",
    "with open(MOUSE_ID_TRACKER_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    mouse_id_map = {int(k): v for k, v in json.load(f).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cfba7be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 104/104 [00:12<00:00,  8.46it/s]\n"
     ]
    }
   ],
   "source": [
    "reverse_lookup = precompute_reverse_matches(\n",
    "    target_terms=human_terms,\n",
    "    reverse_index=mouse_index,\n",
    "    reverse_id_map=mouse_id_map,\n",
    "    model=embedding_model,\n",
    "    top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d4027746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 104/104 [00:12<00:00,  8.45it/s]\n"
     ]
    }
   ],
   "source": [
    "reverse_lookup_topk = precompute_reverse_matches_topk(\n",
    "    target_terms=human_terms,\n",
    "    reverse_index=mouse_index,\n",
    "    reverse_id_map=mouse_id_map,\n",
    "    model=embedding_model,\n",
    "    top_k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "962260bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3298"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reverse_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "39c1f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./data/datasets/anatomy-dataset/reverse_lookup.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(reverse_lookup, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "abcf5460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hcb(matches, reverse_lookup, fallback_threshold=0.95):\n",
    "    filtered = []\n",
    "    skipped_top_match = 0\n",
    "    no_predicited_uri = 0\n",
    "    for m in matches:\n",
    "        source_uri = m[\"source_uri\"]\n",
    "        top_match = m.get(\"top_match\")\n",
    "\n",
    "        if not top_match:\n",
    "            skipped_top_match += 1\n",
    "            continue\n",
    "\n",
    "        predicted_uri = top_match[\"uri\"]\n",
    "        confidence = top_match.get(\"combined_score\", top_match.get(\"score\", 0))\n",
    "\n",
    "        if reverse_lookup.get(predicted_uri) == source_uri:\n",
    "            filtered.append(m)  # standard HCB\n",
    "        elif confidence >= fallback_threshold:\n",
    "            filtered.append(m)  # allow fallback based on confidence\n",
    "        else: \n",
    "            no_predicited_uri += 1\n",
    "\n",
    "    print(f\"skipped_top_match {skipped_top_match}\")\n",
    "    print(f\"no_predicited_uri {no_predicited_uri}\")\n",
    "\n",
    "    return filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "78e88f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hcb_with_topk(matches, reverse_lookup_top1, reverse_lookup_topk):\n",
    "    \"\"\"\n",
    "    Filters matches using bidirectional match (HCB), extended to top-k reverse lookup and confidence fallback.\n",
    "    \n",
    "    Args:\n",
    "        matches: list of match dicts (with top_match + score)\n",
    "        reverse_lookup_top1: dict[target_uri → best source_uri]\n",
    "        reverse_lookup_topk: dict[target_uri → list of top-k source_uris]\n",
    "        fallback_threshold: minimum score to allow fallback if HCB fails\n",
    "\n",
    "    Returns:\n",
    "        List of filtered matches\n",
    "    \"\"\"\n",
    "    filtered = []\n",
    "    stats = {\n",
    "        \"strict_hcb\": 0,\n",
    "        \"semi_hcb\": 0,\n",
    "        \"skipped\": 0\n",
    "    }\n",
    "\n",
    "    for m in matches:\n",
    "        source_uri = m[\"source_uri\"]\n",
    "        top_match = m.get(\"top_match\")\n",
    "\n",
    "        if not top_match:\n",
    "            stats[\"skipped\"] += 1\n",
    "            continue\n",
    "\n",
    "        predicted_uri = top_match[\"uri\"]\n",
    "\n",
    "        if reverse_lookup_top1.get(predicted_uri) == source_uri:\n",
    "            filtered.append(m)\n",
    "            stats[\"strict_hcb\"] += 1\n",
    "        elif source_uri in reverse_lookup_topk.get(predicted_uri, []):\n",
    "            filtered.append(m)\n",
    "            stats[\"semi_hcb\"] += 1\n",
    "        else:\n",
    "            stats[\"skipped\"] += 1\n",
    "\n",
    "    print(\"HCB Filtering Summary:\")\n",
    "    for key, count in stats.items():\n",
    "        print(f\"  {key}: {count}\")\n",
    "\n",
    "    return filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2457c579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HCB Filtering Summary:\n",
      "  strict_hcb: 925\n",
      "  semi_hcb: 376\n",
      "  skipped: 1436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1301"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = apply_hcb_with_topk(matches, reverse_lookup, reverse_lookup_topk)\n",
    "\n",
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bca9ed0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching complete. Results saved to ./data/datasets/anatomy-dataset/mouse_to_human_matches_3.json\n"
     ]
    }
   ],
   "source": [
    "output_path = \"./data/datasets/anatomy-dataset/mouse_to_human_matches_3.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(matches, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Matching complete. Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d198b",
   "metadata": {},
   "source": [
    "#### Prepare gold mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4c422fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/datasets/anatomy-dataset/mouse_testset.json', 1497)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALIGN = Namespace(\"http://knowledgeweb.semanticweb.org/heterogeneity/alignment\")\n",
    "\n",
    "gold_mappings = {}\n",
    "for cell in alignment_graph.subjects(RDF.type, ALIGN.Cell):\n",
    "    mouse_uri = alignment_graph.value(cell, ALIGN.entity1)\n",
    "    human_uri = alignment_graph.value(cell, ALIGN.entity2)\n",
    "    if isinstance(mouse_uri, URIRef) and isinstance(human_uri, URIRef):\n",
    "        gold_mappings[str(mouse_uri)] = str(human_uri)\n",
    "\n",
    "testset = []\n",
    "for s in mouse_graph.subjects(RDF.type, OWL.Class):\n",
    "    label = mouse_graph.value(s, RDFS.label)\n",
    "    comment = mouse_graph.value(s, RDFS.comment)\n",
    "    if label:\n",
    "        entry = {\n",
    "            \"uri\": str(s),\n",
    "            \"label\": str(label),\n",
    "            \"description\": str(comment) if isinstance(comment, Literal) else \"\",\n",
    "            \"gold_uri\": gold_mappings.get(str(s), \"\")\n",
    "        }\n",
    "        if entry[\"gold_uri\"]:\n",
    "            testset.append(entry)\n",
    "\n",
    "with open(TESTSET_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(testset, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "TESTSET_PATH, len(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b6072b",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b60f2230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OAEI Standard Evaluation\n",
      "Precision: 76.92%\n",
      "Recall:    60.12%\n",
      "F1 Score:  67.49%\n",
      "TP: 900  FP: 270  FN: 597\n",
      "\n",
      "Relaxed Evaluation (Only matched entries)\n",
      "Precision: 90.91%\n",
      "Recall:    100.00%\n",
      "F1 Score:  95.24%\n",
      "TP: 900  FP: 90  FN: 0\n",
      "\n",
      "Counts\n",
      "Total predictions attempted: 1301\n",
      "Total in gold reference:     1497\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "THRESHOLD = 0.8\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def evaluate_predictions(matches, gold_lookup, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Evaluates predictions in three ways:\n",
    "    1. OAEI Standard (default): Any confident prediction not matching gold = FP\n",
    "    2. Relaxed: Skip evaluation if gold is missing\n",
    "    3. Strict: Also penalize confident predictions for entries missing in gold\n",
    "    \"\"\"\n",
    "    TP_oaei = FP_oaei = FN_oaei = 0\n",
    "    TP_relaxed = FP_relaxed = FN_relaxed = 0\n",
    "    total_predicted = 0\n",
    "\n",
    "    for m in matches:\n",
    "        mouse_uri = m[\"source_uri\"]\n",
    "        mouse_label = m[\"source_label\"]\n",
    "        top_k = m.get(\"top_k_matches\", [])\n",
    "        total_predicted += 1\n",
    "\n",
    "        # reranked = rerank_by_label_similarity(mouse_label, top_k, 0.8, 0.2)\n",
    "        reranked = top_k\n",
    "        if not reranked or not reranked[0]:\n",
    "            continue\n",
    "\n",
    "        top_match = reranked[0]\n",
    "        if top_match[\"combined_score\"] < threshold:\n",
    "            continue  # Not confident enough → not considered a prediction\n",
    "\n",
    "        predicted_uri = top_match[\"uri\"]\n",
    "        gold_uri = gold_lookup.get(mouse_uri)\n",
    "\n",
    "        # OAEI standard: penalize all confident predictions not matching gold\n",
    "        if gold_uri is None:\n",
    "            FP_oaei += 1\n",
    "        elif predicted_uri == gold_uri:\n",
    "            TP_oaei += 1\n",
    "        else:\n",
    "            FP_oaei += 1\n",
    "\n",
    "        # Relaxed evaluation (only where gold exists)\n",
    "        if gold_uri:\n",
    "            if predicted_uri == gold_uri:\n",
    "                TP_relaxed += 1\n",
    "            else:\n",
    "                FP_relaxed += 1\n",
    "        # Relaxed FN still computed\n",
    "        elif gold_uri and top_match[\"combined_score\"] < threshold:\n",
    "            FN_relaxed += 1\n",
    "\n",
    "    # Compute total gold for recall\n",
    "    total_gold = len(gold_lookup)\n",
    "    FN_oaei = total_gold - TP_oaei\n",
    "\n",
    "    # Metrics\n",
    "    def metrics(tp, fp, fn):\n",
    "        prec = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "        rec = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "        f1 = 2 * prec * rec / (prec + rec) if prec + rec > 0 else 0\n",
    "        return prec, rec, f1\n",
    "\n",
    "    oaei = metrics(TP_oaei, FP_oaei, FN_oaei)\n",
    "    relaxed = metrics(TP_relaxed, FP_relaxed, FN_relaxed)\n",
    "\n",
    "    return {\n",
    "        \"OAEI\": {\"TP\": TP_oaei, \"FP\": FP_oaei, \"FN\": FN_oaei, \"metrics\": oaei},\n",
    "        \"Relaxed\": {\"TP\": TP_relaxed, \"FP\": FP_relaxed, \"FN\": FN_relaxed, \"metrics\": relaxed},\n",
    "        \"Counts\": {\"Total predicted\": total_predicted, \"Total gold\": total_gold}\n",
    "    }\n",
    "\n",
    "def print_report(result):\n",
    "    print(\"OAEI Standard Evaluation\")\n",
    "    p, r, f = result[\"OAEI\"][\"metrics\"]\n",
    "    print(f\"Precision: {p:.2%}\")\n",
    "    print(f\"Recall:    {r:.2%}\")\n",
    "    print(f\"F1 Score:  {f:.2%}\")\n",
    "    print(f\"TP: {result['OAEI']['TP']}  FP: {result['OAEI']['FP']}  FN: {result['OAEI']['FN']}\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"Relaxed Evaluation (Only matched entries)\")\n",
    "    p, r, f = result[\"Relaxed\"][\"metrics\"]\n",
    "    print(f\"Precision: {p:.2%}\")\n",
    "    print(f\"Recall:    {r:.2%}\")\n",
    "    print(f\"F1 Score:  {f:.2%}\")\n",
    "    print(f\"TP: {result['Relaxed']['TP']}  FP: {result['Relaxed']['FP']}  FN: {result['Relaxed']['FN']}\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"Counts\")\n",
    "    print(f\"Total predictions attempted: {result['Counts']['Total predicted']}\")\n",
    "    print(f\"Total in gold reference:     {result['Counts']['Total gold']}\")\n",
    "\n",
    "\n",
    "matches = load_json(\"./data/datasets/anatomy-dataset/mouse_to_human_matches_3.json\")\n",
    "testset = load_json(\"./data/datasets/anatomy-dataset/mouse_testset.json\")\n",
    "gold_lookup = {entry[\"uri\"]: entry[\"gold_uri\"] for entry in testset}\n",
    "\n",
    "evaluation_result = evaluate_predictions(matches, gold_lookup, threshold=THRESHOLD)\n",
    "print_report(evaluation_result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ckanenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
