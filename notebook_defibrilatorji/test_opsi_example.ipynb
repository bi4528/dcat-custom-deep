{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e23c27",
   "metadata": {},
   "source": [
    "# OPSI Ontology Matching Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cdfb07",
   "metadata": {},
   "source": [
    "## Setup & Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046417c3",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "789e3d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, RDFS, RDF, OWL, Literal, Namespace\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import yaml\n",
    "from typing import List, Dict, Optional\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rapidfuzz import fuzz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4a1b26",
   "metadata": {},
   "source": [
    "#### Load paths and constans from configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9118162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH = \"notebook_defibrilatorji/source/trbovlje_target.json\"\n",
    "SOURCE_INDEX_PATH = \"notebook_defibrilatorji/source/source_index.faiss\"\n",
    "SOURCE_ID_TRACKER_PATH = \"notebook_defibrilatorji/source/source_tracker.faiss\"\n",
    "TARGET_PATH = \"notebook_defibrilatorji/target/defibrilatorji_target.json\"\n",
    "TARGET_INDEX_PATH = \"notebook_defibrilatorji/target/target_index.faiss\"\n",
    "TARGET_ID_TRACKER_PATH = \"notebook_defibrilatorji/target/target_tracker.faiss\"\n",
    "OUTPUT_PATH = \"notebook_defibrilatorji/result/result_defibrilatorji.json\"\n",
    "EMBEDDING_MODEL_NAME = \"intfloat/multilingual-e5-large\"\n",
    "TOP_K = 3\n",
    "HCB_ENABLED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d533de",
   "metadata": {},
   "source": [
    "#### Utils functions for ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "26e52721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7b591d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(path):\n",
    "    graph = Graph()\n",
    "    graph.parse(path)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "89b9a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(graph, uri):\n",
    "    label = graph.value(uri, RDFS.label)\n",
    "    return str(label) if isinstance(label, Literal) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a86a2dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_related_uris(graph, subject, predicate):\n",
    "    \"\"\"Dereferences URIs linked by the predicate and returns their rdfs:label.\"\"\"\n",
    "    values = []\n",
    "    for obj in graph.objects(subject, predicate):\n",
    "        label = get_label(graph, obj)\n",
    "        if label:\n",
    "            values.append(label)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "93f7df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_superclass_labels(graph, subject):\n",
    "    \"\"\"Get human-readable labels of direct superclasses.\"\"\"\n",
    "    super_labels = []\n",
    "    for superclass in graph.objects(subject, RDFS.subClassOf):\n",
    "        if isinstance(superclass, URIRef):\n",
    "            label = get_label(graph, superclass)\n",
    "            if label:\n",
    "                super_labels.append(label)\n",
    "        elif (superclass, RDF.type, OWL.Restriction) in graph:\n",
    "            filler = graph.value(superclass, OWL.someValuesFrom)\n",
    "            if isinstance(filler, URIRef):\n",
    "                super_labels.append(str(filler).split(\"#\")[-1])\n",
    "    return super_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fffb06",
   "metadata": {},
   "source": [
    "#### Utils functions for generating terms JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4a4491df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_text_for_embedding(label, definition=None, synonyms=None, superclasses=None):\n",
    "    parts = [f\"Concept: {label}\"]\n",
    "\n",
    "    if synonyms:\n",
    "        parts.append(f\"Also known as: {', '.join(synonyms)}\")\n",
    "\n",
    "    if superclasses:\n",
    "        parts.append(f\"Part of: {', '.join(superclasses)}\")\n",
    "\n",
    "    if definition:\n",
    "        parts.append(f\"Defined as: {definition}\")\n",
    "\n",
    "    return \". \".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2a3542f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_enriched_terms(graph):\n",
    "    terms = []\n",
    "    for s in graph.subjects(RDF.type, OWL.Class):\n",
    "        label = get_label(graph, s)\n",
    "        if not label:\n",
    "            continue\n",
    "\n",
    "        definition = extract_related_uris(graph, s, OBO.hasDefinition)\n",
    "        synonyms = extract_related_uris(graph, s, OBO.hasRelatedSynonym)\n",
    "        superclasses = extract_superclass_labels(graph, s)\n",
    "\n",
    "        enriched_text = build_text_for_embedding(\n",
    "            label=label,\n",
    "            definition=definition[0] if definition else None,\n",
    "            synonyms=synonyms,\n",
    "            superclasses=superclasses\n",
    "        )\n",
    "\n",
    "        terms.append({\n",
    "            \"uri\": str(s),\n",
    "            \"label\": label,\n",
    "            \"definition\": definition[0] if definition else \"\",\n",
    "            \"synonyms\": synonyms,\n",
    "            \"superclasses\": superclasses,\n",
    "            \"text_for_embedding\": enriched_text\n",
    "        })\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a8cb1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_embeddings(embeddings: np.ndarray) -> np.ndarray:\n",
    "    return embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2d9c7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ontology_indexing(ontology_json, faiss_index_path, id_tracker_json):\n",
    "\n",
    "    with open(ontology_json, \"r\", encoding=\"utf-8\") as f:\n",
    "            ontology_terms = json.load(f)\n",
    "\n",
    "    texts = []\n",
    "    ids = []\n",
    "    valid_terms = []\n",
    "\n",
    "    for i, term in enumerate(ontology_terms):\n",
    "        text = term.get(\"text_for_embedding\")\n",
    "        if not text:\n",
    "            raise ValueError(\"Missing 'text_for_embedding'\")\n",
    "        texts.append(text)\n",
    "        ids.append(abs(hash(term[\"uri\"])) % (10**12))\n",
    "        valid_terms.append(term)\n",
    "\n",
    "    # Embedding\n",
    "    model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "    embeddings = model.encode(texts, batch_size=16, show_progress_bar=True)\n",
    "    embeddings = normalize_embeddings(np.array(embeddings))\n",
    "\n",
    "    # FAISS indexing\n",
    "    dimension = embeddings.shape[1]\n",
    "    base_index = faiss.IndexFlatIP(dimension)\n",
    "    index = faiss.IndexIDMap(base_index)\n",
    "    index.add_with_ids(embeddings, np.array(ids))\n",
    "    os.makedirs(os.path.dirname(faiss_index_path), exist_ok=True)\n",
    "    faiss.write_index(index, faiss_index_path)\n",
    "\n",
    "    # Save ID tracker\n",
    "    id_map = {str(id_): term for id_, term in zip(ids, valid_terms)}\n",
    "    with open(id_tracker_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(id_map, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432b5389",
   "metadata": {},
   "source": [
    "#### Utils for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0d55dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_by_label_similarity(source_label: str, candidates: List[Dict], weight_faiss: float = 0.7, weight_label: float = 0.3) -> List[Dict]:\n",
    "    \"\"\"Combines semantic score and lexical similarity to rerank matches.\"\"\"\n",
    "    reranked = []\n",
    "    for match in candidates:\n",
    "        label_sim = fuzz.ratio(source_label, match[\"label\"]) / 100\n",
    "        combined_score = weight_faiss * match[\"score\"] + weight_label * label_sim\n",
    "        reranked.append({**match, \"combined_score\": combined_score})\n",
    "    return sorted(reranked, key=lambda x: x[\"combined_score\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "23ca8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index_lookup(index_path: str, id_tracker_path: str):\n",
    "    index = faiss.read_index(index_path)\n",
    "    with open(id_tracker_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        id_map = {int(k): v for k, v in json.load(f).items()}\n",
    "    return index, id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "727dc5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faiss_batch_search(embeddings: np.ndarray, index, top_k: int):\n",
    "    return index.search(embeddings, top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "54b1ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_reverse_matches(\n",
    "    target_terms: List[Dict],\n",
    "    reverse_index,\n",
    "    reverse_id_map: Dict[int, Dict],\n",
    "    model,\n",
    "    top_k: int = 1\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Computes best reverse matches (target → source).\n",
    "    Returns dict: target_uri → best source_uri.\n",
    "    \"\"\"\n",
    "    reverse_lookup = {}\n",
    "\n",
    "    valid_terms = [t for t in target_terms if t.get(\"text_for_embedding\")]\n",
    "    texts = [t[\"text_for_embedding\"] for t in valid_terms]\n",
    "    uris = [t[\"uri\"] for t in valid_terms]\n",
    "\n",
    "    # Batch encoding\n",
    "    embeddings = model.encode(texts, batch_size=32, show_progress_bar=True)\n",
    "    embeddings = normalize_embeddings(np.array(embeddings).astype(np.float32))\n",
    "\n",
    "    # Batch FAISS search\n",
    "    D, I = reverse_index.search(embeddings, top_k)\n",
    "\n",
    "    for i, (indices, scores) in enumerate(zip(I, D)):\n",
    "        best_idx = indices[0]\n",
    "        if best_idx == -1:\n",
    "            continue\n",
    "        match = reverse_id_map.get(best_idx)\n",
    "        if match:\n",
    "            reverse_lookup[uris[i]] = match[\"uri\"]\n",
    "\n",
    "    return reverse_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "329a0e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_reverse_matches_topk(\n",
    "    target_terms: list,\n",
    "    reverse_index,\n",
    "    reverse_id_map: dict,\n",
    "    model,\n",
    "    top_k: int = 5\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Computes top-k reverse matches (target → source).\n",
    "    Returns dict: target_uri → list of source_uris.\n",
    "    \"\"\"\n",
    "    reverse_lookup_k = {}\n",
    "\n",
    "    valid_terms = [t for t in target_terms if t.get(\"text_for_embedding\")]\n",
    "    texts = [t[\"text_for_embedding\"] for t in valid_terms]\n",
    "    uris = [t[\"uri\"] for t in valid_terms]\n",
    "\n",
    "    # Batch encoding\n",
    "    embeddings = model.encode(texts, batch_size=32, show_progress_bar=True)\n",
    "    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "\n",
    "    # Batch FAISS search\n",
    "    D, I = reverse_index.search(np.array(embeddings).astype(np.float32), top_k)\n",
    "\n",
    "    for i, indices in enumerate(I):\n",
    "        matches = [reverse_id_map[idx][\"uri\"] for idx in indices if idx != -1 and reverse_id_map.get(idx)]\n",
    "        reverse_lookup_k[uris[i]] = matches\n",
    "\n",
    "    return reverse_lookup_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f3d2c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_terms(terms: List[Dict], model) -> np.ndarray:\n",
    "    texts = [t[\"text_for_embedding\"] for t in terms if t.get(\"text_for_embedding\")]\n",
    "    return normalize_embeddings(model.encode(texts, batch_size=32, show_progress_bar=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "06e062ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_faiss_results(source_terms, D, I, target_id_map):\n",
    "    matches = []\n",
    "    for i, (distances, indices) in enumerate(zip(D, I)):\n",
    "        src = source_terms[i]\n",
    "        results = []\n",
    "        for idx, score in zip(indices, distances):\n",
    "            if idx == -1:\n",
    "                continue\n",
    "            t = target_id_map.get(idx)\n",
    "            if not t:\n",
    "                continue\n",
    "            results.append({\n",
    "                \"uri\": t[\"uri\"],\n",
    "                \"label\": t[\"label\"],\n",
    "                \"score\": float(score)\n",
    "            })\n",
    "        matches.append({\n",
    "            \"source_uri\": src[\"uri\"],\n",
    "            \"source_label\": src[\"label\"],\n",
    "            \"top_k_matches\": results\n",
    "        })\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8c54f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_label_reranking(matches: List[Dict]):\n",
    "    reranked = []\n",
    "    for match in matches:\n",
    "        ranked = rerank_by_label_similarity(match[\"source_label\"], match[\"top_k_matches\"])\n",
    "        match[\"top_k_matches\"] = ranked\n",
    "        match[\"top_match\"] = ranked[0] if ranked else None\n",
    "        reranked.append(match)\n",
    "    return reranked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ffeab",
   "metadata": {},
   "source": [
    "#### Loading RDF into graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b776c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_graph = load_json(\"notebook_defibrilatorji/source/trbovlje_target.json\")\n",
    "target_graph = load_json(TARGET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf48b3",
   "metadata": {},
   "source": [
    "#### Loading embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c0e6e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ee7dabe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'uri': 'defib:zap_št',\n",
       "  'label': 'ZAP ŠT.',\n",
       "  'definition': 'Stolpec »ZAP ŠT.« predstavlja zaporedno številko defibrilatorja na Krškem.',\n",
       "  'synonyms': [],\n",
       "  'superclasses': [],\n",
       "  'text_for_embedding': 'Concept: ZAP ŠT.. Type: xsd:decimal. Examples: 1.0, 2.0, 3.0. Defined as: Stolpec »ZAP ŠT.« predstavlja zaporedno številko defibrilatorja na Krškem.'},\n",
       " {'uri': 'defib:lokacija',\n",
       "  'label': 'LOKACIJA',\n",
       "  'definition': 'Atribut »LOKACIJA« (opisna lastnost defibrilatorja).',\n",
       "  'synonyms': [],\n",
       "  'superclasses': [],\n",
       "  'text_for_embedding': 'Concept: LOKACIJA. Type: xsd:string. Examples: Brezje v Podboèju, Dom starejših obèanov Krško, Gasilski dom Gora. Defined as: Stolpec »LOKACIJA« predstavlja lokacijo defibrilatorja na Krškem.'},\n",
       " {'uri': 'defib:naslov',\n",
       "  'label': 'NASLOV',\n",
       "  'definition': 'Atribut »NASLOV« (opisna lastnost defibrilatorja).',\n",
       "  'synonyms': [],\n",
       "  'superclasses': [],\n",
       "  'text_for_embedding': 'Concept: NASLOV. Type: xsd:string. Examples: Kje: Brezje v Podboèju 6, 8312 Podboèje, Kje: Kovinarska 13, 8270 Krško, Kje: Gora 31, 8270 Krško. Defined as: Stolpec »NASLOV« predstavlja naslov lokacije defibrilatorja na Krškem.'}]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038506e9",
   "metadata": {},
   "source": [
    "#### Generate enriched JSON of ontology terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d7e9de",
   "metadata": {},
   "source": [
    "Generate enriched terms for human ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ed3f5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_terms = target_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3e4d5ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd135321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b79e09ec",
   "metadata": {},
   "source": [
    "Generate enriched terms for mouse ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5658b75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_terms = source_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f2e313ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327aca2",
   "metadata": {},
   "source": [
    "#### Ontology indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68942e1f",
   "metadata": {},
   "source": [
    "Create and populate FAISS with human entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8c1e2b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.34it/s]\n"
     ]
    }
   ],
   "source": [
    "ontology_indexing(ontology_json=TARGET_PATH, faiss_index_path=TARGET_INDEX_PATH, id_tracker_json=TARGET_ID_TRACKER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f5a39c",
   "metadata": {},
   "source": [
    "Create and populate FAISS with mouse entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "57e43803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.74it/s]\n"
     ]
    }
   ],
   "source": [
    "ontology_indexing(ontology_json=SOURCE_PATH, faiss_index_path=SOURCE_INDEX_PATH, id_tracker_json=SOURCE_ID_TRACKER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e0478",
   "metadata": {},
   "source": [
    "#### Execute matching on mouse human pair of ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ed62e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_index = faiss.read_index(TARGET_INDEX_PATH)\n",
    "with open(TARGET_ID_TRACKER_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    target_id_map = {int(k): v for k, v in json.load(f).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d373bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_index = faiss.read_index(SOURCE_INDEX_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b705e5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.16it/s]\n"
     ]
    }
   ],
   "source": [
    "embs = embed_terms(source_terms, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c7f0a5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.16it/s]\n"
     ]
    }
   ],
   "source": [
    "embs_h = embed_terms(target_terms, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "884de1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "15effa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len match: 8\n",
      "len match: 8\n"
     ]
    }
   ],
   "source": [
    "# Step-by-step matching\n",
    "D, I = faiss_batch_search(embs, target_index, top_k=5)\n",
    "matches = map_faiss_results(source_terms, D, I, target_id_map)\n",
    "\n",
    "output_path = \"./notebook/result/mouse_to_human_matches_unranked.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(matches, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"len match: {len(matches)}\")\n",
    "\n",
    "# Optional refinements\n",
    "matches = apply_label_reranking(matches)\n",
    "\n",
    "output_path = \"./notebook/result/mouse_to_human_matches_ranked.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(matches, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"len match: {len(matches)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "98265564",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_index = faiss.read_index(SOURCE_INDEX_PATH)\n",
    "with open(SOURCE_ID_TRACKER_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    mouse_id_map = {int(k): v for k, v in json.load(f).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "cfba7be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.08it/s]\n"
     ]
    }
   ],
   "source": [
    "reverse_lookup = precompute_reverse_matches(\n",
    "    target_terms=target_terms,\n",
    "    reverse_index=mouse_index,\n",
    "    reverse_id_map=mouse_id_map,\n",
    "    model=embedding_model,\n",
    "    top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d4027746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.74it/s]\n"
     ]
    }
   ],
   "source": [
    "reverse_lookup_topk = precompute_reverse_matches_topk(\n",
    "    target_terms=target_terms,\n",
    "    reverse_index=mouse_index,\n",
    "    reverse_id_map=mouse_id_map,\n",
    "    model=embedding_model,\n",
    "    top_k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "962260bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reverse_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "39c1f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./notebook/result/reverse_lookup.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(reverse_lookup, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "abcf5460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hcb(matches, reverse_lookup, fallback_threshold=0.95):\n",
    "    filtered = []\n",
    "    skipped_top_match = 0\n",
    "    no_predicited_uri = 0\n",
    "    for m in matches:\n",
    "        source_uri = m[\"source_uri\"]\n",
    "        top_match = m.get(\"top_match\")\n",
    "\n",
    "        if not top_match:\n",
    "            skipped_top_match += 1\n",
    "            continue\n",
    "\n",
    "        predicted_uri = top_match[\"uri\"]\n",
    "        confidence = top_match.get(\"combined_score\", top_match.get(\"score\", 0))\n",
    "\n",
    "        if reverse_lookup.get(predicted_uri) == source_uri:\n",
    "            filtered.append(m)  # standard HCB\n",
    "        elif confidence >= fallback_threshold:\n",
    "            filtered.append(m)  # allow fallback based on confidence\n",
    "        else: \n",
    "            no_predicited_uri += 1\n",
    "\n",
    "    print(f\"skipped_top_match {skipped_top_match}\")\n",
    "    print(f\"no_predicited_uri {no_predicited_uri}\")\n",
    "\n",
    "    return filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "78e88f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hcb_with_topk(matches, reverse_lookup_top1, reverse_lookup_topk):\n",
    "    \"\"\"\n",
    "    Filters matches using bidirectional match (HCB), extended to top-k reverse lookup and confidence fallback.\n",
    "    \n",
    "    Args:\n",
    "        matches: list of match dicts (with top_match + score)\n",
    "        reverse_lookup_top1: dict[target_uri → best source_uri]\n",
    "        reverse_lookup_topk: dict[target_uri → list of top-k source_uris]\n",
    "        fallback_threshold: minimum score to allow fallback if HCB fails\n",
    "\n",
    "    Returns:\n",
    "        List of filtered matches\n",
    "    \"\"\"\n",
    "    filtered = []\n",
    "    stats = {\n",
    "        \"strict_hcb\": 0,\n",
    "        \"semi_hcb\": 0,\n",
    "        \"skipped\": 0\n",
    "    }\n",
    "\n",
    "    for m in matches:\n",
    "        source_uri = m[\"source_uri\"]\n",
    "        top_match = m.get(\"top_match\")\n",
    "\n",
    "        if not top_match:\n",
    "            stats[\"skipped\"] += 1\n",
    "            continue\n",
    "\n",
    "        predicted_uri = top_match[\"uri\"]\n",
    "\n",
    "        if reverse_lookup_top1.get(predicted_uri) == source_uri:\n",
    "            filtered.append(m)\n",
    "            stats[\"strict_hcb\"] += 1\n",
    "        elif source_uri in reverse_lookup_topk.get(predicted_uri, []):\n",
    "            filtered.append(m)\n",
    "            stats[\"semi_hcb\"] += 1\n",
    "        else:\n",
    "            stats[\"skipped\"] += 1\n",
    "\n",
    "    print(\"HCB Filtering Summary:\")\n",
    "    for key, count in stats.items():\n",
    "        print(f\"  {key}: {count}\")\n",
    "\n",
    "    return filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2457c579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HCB Filtering Summary:\n",
      "  strict_hcb: 2\n",
      "  semi_hcb: 3\n",
      "  skipped: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = apply_hcb_with_topk(matches, reverse_lookup, reverse_lookup_topk)\n",
    "\n",
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bca9ed0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching complete. Results saved to ./notebook_defibrilatorji/result/defibrilatorji_match.json\n"
     ]
    }
   ],
   "source": [
    "output_path = \"./notebook_defibrilatorji/result/defibrilatorji_match.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(matches, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Matching complete. Results saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ckanenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
